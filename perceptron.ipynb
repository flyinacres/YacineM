{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":3966491,"datasetId":2354152}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-05T04:23:22.787249Z","iopub.execute_input":"2024-03-05T04:23:22.787658Z","iopub.status.idle":"2024-03-05T04:23:23.269395Z","shell.execute_reply.started":"2024-03-05T04:23:22.787620Z","shell.execute_reply":"2024-03-05T04:23:23.267857Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"TODO: Go through this in more detail to see how the two implementations vary, and why they give different results.","metadata":{}},{"cell_type":"markdown","source":"Note: Figured out where the input is stored by default...  Note the directory structure.\n\nSince I used a dataset in Kaggle with the same info but slightly different format I had to edit some details to get this all to work.","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/iris-dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:40:43.335844Z","iopub.execute_input":"2024-03-05T09:40:43.336234Z","iopub.status.idle":"2024-03-05T09:40:44.414338Z","shell.execute_reply.started":"2024-03-05T09:40:43.336189Z","shell.execute_reply":"2024-03-05T09:40:44.412957Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"iris.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!head /kaggle/input/iris-dataset/iris.csv","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:40:46.149936Z","iopub.execute_input":"2024-03-05T09:40:46.150378Z","iopub.status.idle":"2024-03-05T09:40:47.179127Z","shell.execute_reply.started":"2024-03-05T09:40:46.150340Z","shell.execute_reply":"2024-03-05T09:40:47.178096Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"sepal_length,sepal_width,petal_length,petal_width,species\n5.1,3.5,1.4,0.2,setosa\n4.9,3.0,1.4,0.2,setosa\n4.7,3.2,1.3,0.2,setosa\n4.6,3.1,1.5,0.2,setosa\n5.0,3.6,1.4,0.2,setosa\n5.4,3.9,1.7,0.4,setosa\n4.6,3.4,1.4,0.3,setosa\n5.0,3.4,1.5,0.2,setosa\n4.4,2.9,1.4,0.2,setosa\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport random\n\n\n# Perceptron with numpy + pandas\n# The guy is great, will definetly give a shoutout\nclass Perceptron():\n    '''\n        Perceptron Learning Algorithm that can be train using a \n        fit and predict methodology with numpy\n    '''\n    \n    def __init__(self):\n        self.weights = []\n        \n    def fit(self, X, y, learning_rate = 0.01, num_iteration = 100):\n        \n        (num_row, num_feature) = X.shape\n        \n        # Randomly initalize the weights\n        self.weights = np.random.rand(num_feature+1) \n\n        # Launch the training algorithm\n        for i in range(num_iteration):\n            \n            # Stochastic Gradient Descent\n            r_i = random.randint(0,num_row-1)\n            row = X[r_i,:] # take the random sample from the dataset\n            yhat = self.predict(row)\n            error = (y[r_i] - yhat) # estimate of the gradient\n            self.weights[0] = self.weights[0] + learning_rate*error*1 # first weight one is the bias\n\n            # Update all parameters after bias\n            for f_i in range(num_feature):\n                self.weights[f_i] = self.weights[f_i] + learning_rate*error*row[f_i]\n                \n            if i % 100 == 0:\n                total_error = 0\n                for r_i in range(num_row):\n                    row = X[r_i,:]\n                    yhat = self.predict(row)\n                    error = (y[r_i] - yhat)\n                    total_error = total_error + error**2\n                mean_error = total_error/num_row\n                print(f\"Iteration {i} with error = {mean_error}\")\n        \n    def predict(self, row):\n            \n        # The activation start with the bias at weights == 0\n        activation = self.weights[0]\n        \n        # We iterate over the weights and the features in the given row\n        for weight, feature in zip(self.weights[1:], row):\n            activation = activation + weight*feature\n            \n        # Heaviside Step Function Activation\n        if activation >= 0.0:\n            return 1.0\n        return 0.0","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:41:02.203019Z","iopub.execute_input":"2024-03-05T09:41:02.203853Z","iopub.status.idle":"2024-03-05T09:41:02.215266Z","shell.execute_reply.started":"2024-03-05T09:41:02.203805Z","shell.execute_reply":"2024-03-05T09:41:02.213811Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Data sets\ndf = pd.read_csv('/kaggle/input/iris-dataset/iris.csv')\n\ndf.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:41:05.891379Z","iopub.execute_input":"2024-03-05T09:41:05.891763Z","iopub.status.idle":"2024-03-05T09:41:05.919450Z","shell.execute_reply.started":"2024-03-05T09:41:05.891729Z","shell.execute_reply":"2024-03-05T09:41:05.918344Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        sepal_length  sepal_width  petal_length  petal_width species\ncount     150.000000   150.000000    150.000000   150.000000     150\nunique           NaN          NaN           NaN          NaN       3\ntop              NaN          NaN           NaN          NaN  setosa\nfreq             NaN          NaN           NaN          NaN      50\nmean        5.843333     3.054000      3.758667     1.198667     NaN\nstd         0.828066     0.433594      1.764420     0.763161     NaN\nmin         4.300000     2.000000      1.000000     0.100000     NaN\n25%         5.100000     2.800000      1.600000     0.300000     NaN\n50%         5.800000     3.000000      4.350000     1.300000     NaN\n75%         6.400000     3.300000      5.100000     1.800000     NaN\nmax         7.900000     4.400000      6.900000     2.500000     NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843333</td>\n      <td>3.054000</td>\n      <td>3.758667</td>\n      <td>1.198667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.828066</td>\n      <td>0.433594</td>\n      <td>1.764420</td>\n      <td>0.763161</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Do a one hot encoding\ndf = pd.get_dummies(df,prefix='species')\nX = df[['sepal_length','sepal_width','petal_length','petal_width']]\n# Convert the matrix X (note the capitalization) to numpy compatible matrix (no named rows/columns)\nX = X.to_numpy()\n\ndf.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:41:10.262704Z","iopub.execute_input":"2024-03-05T09:41:10.263095Z","iopub.status.idle":"2024-03-05T09:41:10.301442Z","shell.execute_reply.started":"2024-03-05T09:41:10.263059Z","shell.execute_reply":"2024-03-05T09:41:10.300618Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        sepal_length  sepal_width  petal_length  petal_width species_setosa  \\\ncount     150.000000   150.000000    150.000000   150.000000            150   \nunique           NaN          NaN           NaN          NaN              2   \ntop              NaN          NaN           NaN          NaN          False   \nfreq             NaN          NaN           NaN          NaN            100   \nmean        5.843333     3.054000      3.758667     1.198667            NaN   \nstd         0.828066     0.433594      1.764420     0.763161            NaN   \nmin         4.300000     2.000000      1.000000     0.100000            NaN   \n25%         5.100000     2.800000      1.600000     0.300000            NaN   \n50%         5.800000     3.000000      4.350000     1.300000            NaN   \n75%         6.400000     3.300000      5.100000     1.800000            NaN   \nmax         7.900000     4.400000      6.900000     2.500000            NaN   \n\n       species_versicolor species_virginica  \ncount                 150               150  \nunique                  2                 2  \ntop                 False             False  \nfreq                  100               100  \nmean                  NaN               NaN  \nstd                   NaN               NaN  \nmin                   NaN               NaN  \n25%                   NaN               NaN  \n50%                   NaN               NaN  \n75%                   NaN               NaN  \nmax                   NaN               NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species_setosa</th>\n      <th>species_versicolor</th>\n      <th>species_virginica</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843333</td>\n      <td>3.054000</td>\n      <td>3.758667</td>\n      <td>1.198667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.828066</td>\n      <td>0.433594</td>\n      <td>1.764420</td>\n      <td>0.763161</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print('\\nNumpy Array\\n----------\\n', X)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:41:38.073688Z","iopub.execute_input":"2024-03-05T09:41:38.074063Z","iopub.status.idle":"2024-03-05T09:41:38.085927Z","shell.execute_reply.started":"2024-03-05T09:41:38.074023Z","shell.execute_reply":"2024-03-05T09:41:38.084666Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\nNumpy Array\n----------\n [[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.1 1.5 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]\n","output_type":"stream"}]},{"cell_type":"code","source":"y = df.loc[:, 'species_versicolor']\ny = y.to_numpy()\n\n# Shuffle the two dataset in unison by creating a random index vector and applying it to both\nperm = np.random.permutation(len(X))\nX = X[perm]\ny = y[perm]\nprint(perm)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:44:46.188563Z","iopub.execute_input":"2024-03-05T09:44:46.188966Z","iopub.status.idle":"2024-03-05T09:44:46.199548Z","shell.execute_reply.started":"2024-03-05T09:44:46.188936Z","shell.execute_reply":"2024-03-05T09:44:46.198261Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[ 24  69 117 104 121 123 111 136 113 137 103  30   0   1  92   9 114 132\n 115  26  97 135  39 139 131  90 130  71 149  25  46  56 112  78  49  91\n  35   5 142 108  18 120  89  61 140  36   7  43  27 143   8  57  72  74\n  77  48  85  83 148 107  96  17  62  87 146  66 116  76  51  55 144  23\n  37 122  11 141  14 125  63 138   4 110 127  40  99  70  15 126  28  98\n  29  68  73  41 105  45 119  65  33  82  67  47  12  80  34  32 100  60\n   2  50  21  64  75 102  84  19 128  38 101  59  22  95 124  88 106  58\n  52  81 133 129  16  54  42 109  44 134  94   3  13  10  53   6  31  86\n  93 145  79 118  20 147]\n","output_type":"stream"}]},{"cell_type":"code","source":"\nclf = Perceptron()\nclf.fit(X,y, num_iteration = 1000)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:45:24.217589Z","iopub.execute_input":"2024-03-05T09:45:24.217950Z","iopub.status.idle":"2024-03-05T09:45:24.243892Z","shell.execute_reply.started":"2024-03-05T09:45:24.217924Z","shell.execute_reply":"2024-03-05T09:45:24.242792Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Iteration 0 with error = 0.6666666666666666\nIteration 100 with error = 0.36\nIteration 200 with error = 0.5533333333333333\nIteration 300 with error = 0.6\nIteration 400 with error = 0.3333333333333333\nIteration 500 with error = 0.7466666666666667\nIteration 600 with error = 0.38666666666666666\nIteration 700 with error = 0.76\nIteration 800 with error = 0.3466666666666667\nIteration 900 with error = 0.44666666666666666\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\n\nclass Perceptron():\n    '''\n        Perceptron Learning Algorithm that can be train using a \n        fit and predict methodology, without any library\n    '''\n    \n    def __init__(self):\n        self.weights = []\n        \n    def fit(self, X, y, learning_rate = 0.01, num_iteration = 100):\n        \n        num_row = len(X)\n        num_feature = len(X[0]) # Here we assume that we have a rectangular matrix\n        \n        # Randomly initalize the weights\n        for i in range(num_feature+1):\n            self.weights.append(random.uniform(0,1))\n        \n        # Launch the training algorithm\n        \n        for i in range(num_iteration):\n            \n            # Stochastic Gradient Descent\n            r_i = random.randint(0,num_row-1)\n            row = X[r_i]\n            yhat = self.predict(row)\n            error = (y[r_i] - yhat)\n            self.weights[0] = self.weights[0] + learning_rate*error\n\n            for f_i in range(num_feature):\n                self.weights[f_i] = self.weights[f_i] + learning_rate*error*row[f_i]\n                \n            if i % 100 == 0:\n                total_error = 0\n                for r_i in range(num_row):\n                    row = X[r_i]\n                    yhat = self.predict(row)\n                    error = (y[r_i] - yhat)\n                    total_error = total_error + error**2\n                mean_error = total_error/num_row\n                print(f\"Iteration {i} with error = {mean_error}\")\n        \n    def predict(self, row):\n            \n        # The activation start with the bias at weights == 0\n        activation = self.weights[0]\n        \n        # We iterate over the weights and the features in the given row\n        for weight, feature in zip(self.weights[1:], row):\n            activation = activation + weight*feature\n            \n        if activation >= 0.0:\n            return 1.0\n        return 0.0","metadata":{"execution":{"iopub.status.busy":"2024-03-05T04:52:36.337677Z","iopub.execute_input":"2024-03-05T04:52:36.338101Z","iopub.status.idle":"2024-03-05T04:52:36.355275Z","shell.execute_reply.started":"2024-03-05T04:52:36.338068Z","shell.execute_reply":"2024-03-05T04:52:36.353768Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import csv\n\ndef permute_together(X,y):\n    '''\n        Helper function to permute (shuffle) a matrix and a vector together\n    '''\n    \n    perm_X = []\n    perm_y = []\n    while len(X) != 0 and len(y) != 0:\n        \n        perm_id = random.randint(0,len(X)-1)\n        perm_X.append(X.pop(perm_id))\n        perm_y.append(y.pop(perm_id))\n        \n    return (perm_X, perm_y)\n\nclass DataFrame():\n    '''\n        Simple dataframe to mimick the pandas library\n    '''\n    def __init__(self):\n        self.header = [];\n        self.X = []\n        self.y = []\n        \n    def clean_string(self,string):\n        '''\n            Dummy function to clean up the iris dataset from (\")\n        '''\n        return string.replace('\"', '')\n    \n\n    def get_encoded_labels(self, target):\n        '''\n            Encode with 1 or 0 the y vector if it match our target variable\n        '''\n        labels = []\n        for label in self.y:\n            if label == target:\n                labels.append(1)\n            else:\n                labels.append(0)\n        return labels\n    \n    def read_csv(self, filename):\n        '''\n            Read the iris dataset CSV file and populate the header, the X and the y variables\n            needed for the perceptron\n        '''\n        with open(filename, newline='', encoding=\"utf-8-sig\") as csvfile:\n            csvreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n            \n            index = -1\n            for row in csvreader:\n                \n                # We have the header\n                if index == -1:\n                    self.header = [self.clean_string(s) for s in row[0].split(',')]\n                    index += 1\n                    continue\n                \n                # Here is the data\n                x = []\n                target = None\n                data = row[0].split(',')\n                for i in range(len(data)-1):\n                    x.append(float(data[i]))\n                \n                # Last item in the csv will be the target\n                self.y.append(self.clean_string(data[len(data)-1]))\n                self.X.append(x)\n                \n                index += 1\n        \n                \n\n# Data sets\ndf = DataFrame()\ndf.read_csv('/kaggle/input/iris-dataset/iris.csv')\n\nX = df.X\ny = df.get_encoded_labels('Versicolor') # encoding for 0 and 1\n\n# Shuffle the two dataset in unison\nX,y = permute_together(X,y)\n\nclf = Perceptron()\nclf.fit(X,y, num_iteration = 1000)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T04:53:16.717743Z","iopub.execute_input":"2024-03-05T04:53:16.718643Z","iopub.status.idle":"2024-03-05T04:53:16.763033Z","shell.execute_reply.started":"2024-03-05T04:53:16.718600Z","shell.execute_reply":"2024-03-05T04:53:16.761628Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Iteration 0 with error = 1.0\nIteration 100 with error = 0.0\nIteration 200 with error = 0.0\nIteration 300 with error = 0.0\nIteration 400 with error = 0.0\nIteration 500 with error = 0.0\nIteration 600 with error = 0.0\nIteration 700 with error = 0.0\nIteration 800 with error = 0.0\nIteration 900 with error = 0.0\n","output_type":"stream"}]}]}