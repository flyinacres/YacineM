{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":3966491,"datasetId":2354152}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-05T17:26:29.419770Z","iopub.execute_input":"2024-03-05T17:26:29.420156Z","iopub.status.idle":"2024-03-05T17:26:29.904743Z","shell.execute_reply.started":"2024-03-05T17:26:29.420122Z","shell.execute_reply":"2024-03-05T17:26:29.903544Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/iris-dataset/iris.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"TODO: Go through this in more detail to see how the two implementations vary, and why they give different results.","metadata":{}},{"cell_type":"markdown","source":"Note: Figured out where the input is stored by default...  Note the directory structure.\n\nSince I used a dataset in Kaggle with the same info but slightly different format I had to edit some details to get this all to work.","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/iris-dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:40:43.335844Z","iopub.execute_input":"2024-03-05T09:40:43.336234Z","iopub.status.idle":"2024-03-05T09:40:44.414338Z","shell.execute_reply.started":"2024-03-05T09:40:43.336189Z","shell.execute_reply":"2024-03-05T09:40:44.412957Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"iris.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!head /kaggle/input/iris-dataset/iris.csv","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:40:46.149936Z","iopub.execute_input":"2024-03-05T09:40:46.150378Z","iopub.status.idle":"2024-03-05T09:40:47.179127Z","shell.execute_reply.started":"2024-03-05T09:40:46.150340Z","shell.execute_reply":"2024-03-05T09:40:47.178096Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"sepal_length,sepal_width,petal_length,petal_width,species\n5.1,3.5,1.4,0.2,setosa\n4.9,3.0,1.4,0.2,setosa\n4.7,3.2,1.3,0.2,setosa\n4.6,3.1,1.5,0.2,setosa\n5.0,3.6,1.4,0.2,setosa\n5.4,3.9,1.7,0.4,setosa\n4.6,3.4,1.4,0.3,setosa\n5.0,3.4,1.5,0.2,setosa\n4.4,2.9,1.4,0.2,setosa\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Note: Tried to add %debug, then force a break by adding a divide by zero.  The code did halt, but I was unable to get the variables from the fit function. I will probably need to dig into the Python command line debugger to figure out how to do such things, as I cannot find a visual debugger for Kaggle.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\n\n# Perceptron with numpy + pandas\n# The guy is great, will definetly give a shoutout\nclass Perceptron():\n    '''\n        Perceptron Learning Algorithm that can be train using a \n        fit and predict methodology with numpy\n    '''\n    # I added the theta as otherwise the activation function was picking 1.0 as an output with any non-zero\n    # input.  This does not seem to improve results in this simple example.\n    def __init__(self, theta):\n        self.weights = []\n        self.theta = theta\n        \n    def fit(self, X, y, learning_rate = 0.01, num_iteration = 100):\n        \n        # Using the shape of the input features, determine the number of rows and columns\n        (num_row, num_feature) = X.shape\n        \n        # Randomly initalize the weights with a uniform distribution [0,1), to one more than \n        # the number of features, to account for the bias\n        self.weights = np.random.rand(num_feature+1) \n\n        # Launch the training algorithm\n        for i in range(num_iteration):\n            \n            # Stochastic Gradient Descent\n            r_i = random.randint(0,num_row-1)\n            row = X[r_i,:] # take the random sample from the dataset\n            yhat = self.predict(row)\n            error = (y[r_i] - yhat) # estimate of the gradient\n            self.weights[0] = self.weights[0] + learning_rate*error*1 # first weight one is the bias\n\n            # Update all parameters after bias\n            # I changed this to start with range 1 to properly index weights. This works, (and\n            # more closely represents the original code that this was taken from) \n            for f_i in range(1,num_feature+1):\n                self.weights[f_i] = self.weights[f_i] + learning_rate*error*row[f_i-1]\n                \n            if i % 100 == 0:\n                total_error = 0\n                for r_i in range(num_row):\n                    row = X[r_i,:]\n                    yhat = self.predict(row)\n                    error = (y[r_i] - yhat)\n                    total_error = total_error + error**2\n                mean_error = total_error/num_row\n                print(f\"Iteration {i} with error = {mean_error}\")\n        \n    def predict(self, row):\n            \n        # The activation start with the bias at weights == 0\n        activation = self.weights[0]\n        \n        # We iterate over the weights and the features in the given row\n        for weight, feature in zip(self.weights[1:], row):\n            activation = activation + weight*feature\n            \n        # Heaviside Step Function Activation\n        if activation >= self.theta:\n            return 1.0\n        return 0.0","metadata":{"execution":{"iopub.status.busy":"2024-03-05T18:16:58.696533Z","iopub.execute_input":"2024-03-05T18:16:58.696976Z","iopub.status.idle":"2024-03-05T18:16:58.711329Z","shell.execute_reply.started":"2024-03-05T18:16:58.696944Z","shell.execute_reply":"2024-03-05T18:16:58.710321Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Data sets\ndf = pd.read_csv('/kaggle/input/iris-dataset/iris.csv')\n\ndf.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T17:27:42.951468Z","iopub.execute_input":"2024-03-05T17:27:42.951840Z","iopub.status.idle":"2024-03-05T17:27:43.019182Z","shell.execute_reply.started":"2024-03-05T17:27:42.951812Z","shell.execute_reply":"2024-03-05T17:27:43.018033Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        sepal_length  sepal_width  petal_length  petal_width species\ncount     150.000000   150.000000    150.000000   150.000000     150\nunique           NaN          NaN           NaN          NaN       3\ntop              NaN          NaN           NaN          NaN  setosa\nfreq             NaN          NaN           NaN          NaN      50\nmean        5.843333     3.054000      3.758667     1.198667     NaN\nstd         0.828066     0.433594      1.764420     0.763161     NaN\nmin         4.300000     2.000000      1.000000     0.100000     NaN\n25%         5.100000     2.800000      1.600000     0.300000     NaN\n50%         5.800000     3.000000      4.350000     1.300000     NaN\n75%         6.400000     3.300000      5.100000     1.800000     NaN\nmax         7.900000     4.400000      6.900000     2.500000     NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843333</td>\n      <td>3.054000</td>\n      <td>3.758667</td>\n      <td>1.198667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.828066</td>\n      <td>0.433594</td>\n      <td>1.764420</td>\n      <td>0.763161</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Do a one hot encoding\ndf = pd.get_dummies(df,prefix='species')\nX = df[['sepal_length','sepal_width','petal_length','petal_width']]\n# Convert the matrix X (note the capitalization) to numpy compatible matrix (no named rows/columns)\nX = X.to_numpy()\n\ndf.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2024-03-05T17:27:51.514793Z","iopub.execute_input":"2024-03-05T17:27:51.515462Z","iopub.status.idle":"2024-03-05T17:27:51.557632Z","shell.execute_reply.started":"2024-03-05T17:27:51.515420Z","shell.execute_reply":"2024-03-05T17:27:51.556533Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        sepal_length  sepal_width  petal_length  petal_width species_setosa  \\\ncount     150.000000   150.000000    150.000000   150.000000            150   \nunique           NaN          NaN           NaN          NaN              2   \ntop              NaN          NaN           NaN          NaN          False   \nfreq             NaN          NaN           NaN          NaN            100   \nmean        5.843333     3.054000      3.758667     1.198667            NaN   \nstd         0.828066     0.433594      1.764420     0.763161            NaN   \nmin         4.300000     2.000000      1.000000     0.100000            NaN   \n25%         5.100000     2.800000      1.600000     0.300000            NaN   \n50%         5.800000     3.000000      4.350000     1.300000            NaN   \n75%         6.400000     3.300000      5.100000     1.800000            NaN   \nmax         7.900000     4.400000      6.900000     2.500000            NaN   \n\n       species_versicolor species_virginica  \ncount                 150               150  \nunique                  2                 2  \ntop                 False             False  \nfreq                  100               100  \nmean                  NaN               NaN  \nstd                   NaN               NaN  \nmin                   NaN               NaN  \n25%                   NaN               NaN  \n50%                   NaN               NaN  \n75%                   NaN               NaN  \nmax                   NaN               NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species_setosa</th>\n      <th>species_versicolor</th>\n      <th>species_virginica</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843333</td>\n      <td>3.054000</td>\n      <td>3.758667</td>\n      <td>1.198667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.828066</td>\n      <td>0.433594</td>\n      <td>1.764420</td>\n      <td>0.763161</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The following code produces this type of data, if it runs (but the list might be longer than I want to show here):\n\nNumpy Array\n----------\n [[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]","metadata":{}},{"cell_type":"code","source":"#print('\\nNumpy Array\\n----------\\n', X)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:41:38.073688Z","iopub.execute_input":"2024-03-05T09:41:38.074063Z","iopub.status.idle":"2024-03-05T09:41:38.085927Z","shell.execute_reply.started":"2024-03-05T09:41:38.074023Z","shell.execute_reply":"2024-03-05T09:41:38.084666Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\nNumpy Array\n----------\n [[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.1 1.5 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]\n","output_type":"stream"}]},{"cell_type":"code","source":"y = df.loc[:, 'species_versicolor']\ny = y.to_numpy()\n\n# Shuffle the two dataset in unison by creating a random index vector and applying it to both\nperm = np.random.permutation(len(X))\nX = X[perm]\ny = y[perm]\nprint(perm)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T17:28:00.190586Z","iopub.execute_input":"2024-03-05T17:28:00.190993Z","iopub.status.idle":"2024-03-05T17:28:00.201719Z","shell.execute_reply.started":"2024-03-05T17:28:00.190962Z","shell.execute_reply":"2024-03-05T17:28:00.200617Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[ 33  97  39  27  92 144  65 125  34  90  86  82  51  56  74 122 118  31\n  41  37 147  49 145  71   1 106  19 137 142  75  80 141  48  29  21  98\n  99   2 110  18   4 136 114 129  55 143   8 109 130  14 116  62  73  20\n  22  32  63  78 100  83 112 121 139 140   5   7   9 148  84 101  11  10\n 131  13 113  42 149  85  77  53  16  59 128  60  44  67   3  81 133  40\n  88 103 146  26  25  76  46 124  17  89  43 115 102 135  58 120  28  68\n 105  54 104 117  70 138  15 134 127  12 107  57  91  64  95  30  79  66\n 132   0  94  87 123  23  50 126  93  24  52  36  45  38 108 111  69   6\n  61  72  47 119  35  96]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Given that fit is called right after the Perceptron is created, some parameters could be passed to the initializer.\nclf = Perceptron(0.2)\nclf.fit(X,y, num_iteration = 2000)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T18:17:08.944444Z","iopub.execute_input":"2024-03-05T18:17:08.944882Z","iopub.status.idle":"2024-03-05T18:17:09.025037Z","shell.execute_reply.started":"2024-03-05T18:17:08.944837Z","shell.execute_reply":"2024-03-05T18:17:09.023727Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Iteration 0 with error = 0.6666666666666666\nIteration 100 with error = 0.47333333333333333\nIteration 200 with error = 0.3333333333333333\nIteration 300 with error = 0.6666666666666666\nIteration 400 with error = 0.3333333333333333\nIteration 500 with error = 0.3333333333333333\nIteration 600 with error = 0.6666666666666666\nIteration 700 with error = 0.3333333333333333\nIteration 800 with error = 0.6333333333333333\nIteration 900 with error = 0.36666666666666664\nIteration 1000 with error = 0.3333333333333333\nIteration 1100 with error = 0.3333333333333333\nIteration 1200 with error = 0.3466666666666667\nIteration 1300 with error = 0.6666666666666666\nIteration 1400 with error = 0.34\nIteration 1500 with error = 0.6666666666666666\nIteration 1600 with error = 0.30666666666666664\nIteration 1700 with error = 0.5133333333333333\nIteration 1800 with error = 0.64\nIteration 1900 with error = 0.3333333333333333\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Results are not great, and jump back and forth...","metadata":{}},{"cell_type":"code","source":"import random\n\nclass Perceptron():\n    '''\n        Perceptron Learning Algorithm that can be train using a \n        fit and predict methodology, without any library\n    '''\n    \n    def __init__(self):\n        self.weights = []\n        \n    def fit(self, X, y, learning_rate = 0.01, num_iteration = 100):\n        \n        num_row = len(X)\n        num_feature = len(X[0]) # Here we assume that we have a rectangular matrix\n        \n        # Randomly initalize the weights\n        for i in range(num_feature+1):\n            self.weights.append(random.uniform(0,1))\n        \n        # Launch the training algorithm\n        \n        for i in range(num_iteration):\n            \n            # Stochastic Gradient Descent\n            r_i = random.randint(0,num_row-1)\n            row = X[r_i]\n            yhat = self.predict(row)\n            error = (y[r_i] - yhat)\n            self.weights[0] = self.weights[0] + learning_rate*error\n\n            for f_i in range(num_feature):\n                self.weights[f_i] = self.weights[f_i] + learning_rate*error*row[f_i]\n                \n            if i % 100 == 0:\n                total_error = 0\n                for r_i in range(num_row):\n                    row = X[r_i]\n                    yhat = self.predict(row)\n                    error = (y[r_i] - yhat)\n                    total_error = total_error + error**2\n                mean_error = total_error/num_row\n                print(f\"Iteration {i} with error = {mean_error}\")\n        \n    def predict(self, row):\n            \n        # The activation start with the bias at weights == 0\n        activation = self.weights[0]\n        \n        # We iterate over the weights and the features in the given row\n        for weight, feature in zip(self.weights[1:], row):\n            activation = activation + weight*feature\n            \n        if activation >= 0.0:\n            return 1.0\n        return 0.0","metadata":{"execution":{"iopub.status.busy":"2024-03-05T04:52:36.337677Z","iopub.execute_input":"2024-03-05T04:52:36.338101Z","iopub.status.idle":"2024-03-05T04:52:36.355275Z","shell.execute_reply.started":"2024-03-05T04:52:36.338068Z","shell.execute_reply":"2024-03-05T04:52:36.353768Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import csv\n\ndef permute_together(X,y):\n    '''\n        Helper function to permute (shuffle) a matrix and a vector together\n    '''\n    \n    perm_X = []\n    perm_y = []\n    while len(X) != 0 and len(y) != 0:\n        \n        perm_id = random.randint(0,len(X)-1)\n        perm_X.append(X.pop(perm_id))\n        perm_y.append(y.pop(perm_id))\n        \n    return (perm_X, perm_y)\n\nclass DataFrame():\n    '''\n        Simple dataframe to mimick the pandas library\n    '''\n    def __init__(self):\n        self.header = [];\n        self.X = []\n        self.y = []\n        \n    def clean_string(self,string):\n        '''\n            Dummy function to clean up the iris dataset from (\")\n        '''\n        return string.replace('\"', '')\n    \n\n    def get_encoded_labels(self, target):\n        '''\n            Encode with 1 or 0 the y vector if it match our target variable\n        '''\n        labels = []\n        for label in self.y:\n            if label == target:\n                labels.append(1)\n            else:\n                labels.append(0)\n        return labels\n    \n    def read_csv(self, filename):\n        '''\n            Read the iris dataset CSV file and populate the header, the X and the y variables\n            needed for the perceptron\n        '''\n        with open(filename, newline='', encoding=\"utf-8-sig\") as csvfile:\n            csvreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n            \n            index = -1\n            for row in csvreader:\n                \n                # We have the header\n                if index == -1:\n                    self.header = [self.clean_string(s) for s in row[0].split(',')]\n                    index += 1\n                    continue\n                \n                # Here is the data\n                x = []\n                target = None\n                data = row[0].split(',')\n                for i in range(len(data)-1):\n                    x.append(float(data[i]))\n                \n                # Last item in the csv will be the target\n                self.y.append(self.clean_string(data[len(data)-1]))\n                self.X.append(x)\n                \n                index += 1\n        \n                \n\n# Data sets\ndf = DataFrame()\ndf.read_csv('/kaggle/input/iris-dataset/iris.csv')\n\nX = df.X\ny = df.get_encoded_labels('Versicolor') # encoding for 0 and 1\n\n# Shuffle the two dataset in unison\nX,y = permute_together(X,y)\n\nclf = Perceptron()\nclf.fit(X,y, num_iteration = 1000)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T04:53:16.717743Z","iopub.execute_input":"2024-03-05T04:53:16.718643Z","iopub.status.idle":"2024-03-05T04:53:16.763033Z","shell.execute_reply.started":"2024-03-05T04:53:16.718600Z","shell.execute_reply":"2024-03-05T04:53:16.761628Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Iteration 0 with error = 1.0\nIteration 100 with error = 0.0\nIteration 200 with error = 0.0\nIteration 300 with error = 0.0\nIteration 400 with error = 0.0\nIteration 500 with error = 0.0\nIteration 600 with error = 0.0\nIteration 700 with error = 0.0\nIteration 800 with error = 0.0\nIteration 900 with error = 0.0\n","output_type":"stream"}]}]}