{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":3966491,"datasetId":2354152}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-06T18:38:53.349726Z","iopub.execute_input":"2024-03-06T18:38:53.350203Z","iopub.status.idle":"2024-03-06T18:38:53.863347Z","shell.execute_reply.started":"2024-03-06T18:38:53.350156Z","shell.execute_reply":"2024-03-06T18:38:53.861966Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/iris-dataset/iris.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"TODO: Go through this in more detail to see how the two implementations vary, and why they give different results.","metadata":{}},{"cell_type":"markdown","source":"Note: Figured out where the input is stored by default...  Note the directory structure.\n\nSince I used a dataset in Kaggle with the same info but slightly different format I had to edit some details to get this all to work.","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/iris-dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:40:43.335844Z","iopub.execute_input":"2024-03-05T09:40:43.336234Z","iopub.status.idle":"2024-03-05T09:40:44.414338Z","shell.execute_reply.started":"2024-03-05T09:40:43.336189Z","shell.execute_reply":"2024-03-05T09:40:44.412957Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"iris.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!head /kaggle/input/iris-dataset/iris.csv","metadata":{"execution":{"iopub.status.busy":"2024-03-05T09:40:46.149936Z","iopub.execute_input":"2024-03-05T09:40:46.150378Z","iopub.status.idle":"2024-03-05T09:40:47.179127Z","shell.execute_reply.started":"2024-03-05T09:40:46.150340Z","shell.execute_reply":"2024-03-05T09:40:47.178096Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"sepal_length,sepal_width,petal_length,petal_width,species\n5.1,3.5,1.4,0.2,setosa\n4.9,3.0,1.4,0.2,setosa\n4.7,3.2,1.3,0.2,setosa\n4.6,3.1,1.5,0.2,setosa\n5.0,3.6,1.4,0.2,setosa\n5.4,3.9,1.7,0.4,setosa\n4.6,3.4,1.4,0.3,setosa\n5.0,3.4,1.5,0.2,setosa\n4.4,2.9,1.4,0.2,setosa\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Note: Tried to add %debug, then force a break by adding a divide by zero.  The code did halt, but I was unable to get the variables from the fit function. I will probably need to dig into the Python command line debugger to figure out how to do such things, as I cannot find a visual debugger for Kaggle.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\n\n# Perceptron with numpy + pandas\n# The guy is great, will definetly give a shoutout\nclass Perceptron():\n    '''\n        Perceptron Learning Algorithm that can be train using a \n        fit and predict methodology with numpy\n    '''\n    # I added the theta as otherwise the activation function was picking 1.0 as an output with any non-zero\n    # input.  This does not seem to improve results in this simple example.\n    def __init__(self, theta):\n        self.weights = []\n        self.theta = theta\n        \n    def fit(self, X, y, learning_rate = 0.01, num_iteration = 100, feedback = 100):\n        \n        # Using the shape of the input features, determine the number of rows and columns\n        (num_row, num_feature) = X.shape\n        \n        # Randomly initalize the weights with a uniform distribution [0,1), to one more than \n        # the number of features, to account for the bias\n        self.weights = np.random.rand(num_feature+1) \n\n        # Launch the training algorithm\n        for i in range(num_iteration):\n            \n            # Stochastic Gradient Descent\n            # Stochastic as it picks a random row rather than all rows\n            r_i = random.randint(0,num_row-1)\n            row = X[r_i,:] # take the random sample from the dataset\n            yhat = self.predict(row)\n            error = (y[r_i] - yhat) # estimate of the gradient (estimate because algorithm is stochastic)\n            self.weights[0] = self.weights[0] + learning_rate*error*1 # first weight is the bias\n            \n            # Force an error\n            result = 5 / 0\n\n            # Update all parameters after bias\n            # I changed this to start with range 1 to properly index weights. This works, (and\n            # more closely represents the original code that this was taken from) \n            for f_i in range(1,num_feature+1):\n                self.weights[f_i] = self.weights[f_i] + learning_rate*error*row[f_i-1]\n                \n            if i % feedback == 0:\n                total_error = 0\n                for r_i in range(num_row):\n                    row = X[r_i,:]\n                    yhat = self.predict(row)\n                    error = (y[r_i] - yhat)\n                    total_error = total_error + error**2\n                mean_error = total_error/num_row\n                print(f\"Iteration {i} with error = {mean_error}\")\n        \n    def predict(self, row):\n            \n        # The activation start with the bias at weights == 0\n        activation = self.weights[0]\n        \n        # We iterate over the weights and the features in the given row\n        for weight, feature in zip(self.weights[1:], row):\n            activation = activation + weight*feature\n            \n        # Heaviside Step Function Activation\n        if activation >= self.theta:\n            return 1.0\n        return 0.0","metadata":{"execution":{"iopub.status.busy":"2024-03-06T19:05:27.066686Z","iopub.execute_input":"2024-03-06T19:05:27.067138Z","iopub.status.idle":"2024-03-06T19:05:27.082974Z","shell.execute_reply.started":"2024-03-06T19:05:27.067107Z","shell.execute_reply":"2024-03-06T19:05:27.081709Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Data sets\ndf = pd.read_csv('/kaggle/input/iris-dataset/iris.csv')\n\ndf.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2024-03-06T18:39:06.222010Z","iopub.execute_input":"2024-03-06T18:39:06.222907Z","iopub.status.idle":"2024-03-06T18:39:06.293503Z","shell.execute_reply.started":"2024-03-06T18:39:06.222855Z","shell.execute_reply":"2024-03-06T18:39:06.292558Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        sepal_length  sepal_width  petal_length  petal_width species\ncount     150.000000   150.000000    150.000000   150.000000     150\nunique           NaN          NaN           NaN          NaN       3\ntop              NaN          NaN           NaN          NaN  setosa\nfreq             NaN          NaN           NaN          NaN      50\nmean        5.843333     3.054000      3.758667     1.198667     NaN\nstd         0.828066     0.433594      1.764420     0.763161     NaN\nmin         4.300000     2.000000      1.000000     0.100000     NaN\n25%         5.100000     2.800000      1.600000     0.300000     NaN\n50%         5.800000     3.000000      4.350000     1.300000     NaN\n75%         6.400000     3.300000      5.100000     1.800000     NaN\nmax         7.900000     4.400000      6.900000     2.500000     NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843333</td>\n      <td>3.054000</td>\n      <td>3.758667</td>\n      <td>1.198667</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.828066</td>\n      <td>0.433594</td>\n      <td>1.764420</td>\n      <td>0.763161</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Do a one hot encoding\ndf = pd.get_dummies(df,prefix='species')\nX = df[['sepal_length','sepal_width','petal_length','petal_width']]\n# Convert the matrix X (note the capitalization) to numpy compatible matrix (no named rows/columns)\nX = X.to_numpy()\n\ndf.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2024-03-06T18:39:10.569556Z","iopub.execute_input":"2024-03-06T18:39:10.569963Z","iopub.status.idle":"2024-03-06T18:39:10.611293Z","shell.execute_reply.started":"2024-03-06T18:39:10.569932Z","shell.execute_reply":"2024-03-06T18:39:10.610451Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        sepal_length  sepal_width  petal_length  petal_width species_setosa  \\\ncount     150.000000   150.000000    150.000000   150.000000            150   \nunique           NaN          NaN           NaN          NaN              2   \ntop              NaN          NaN           NaN          NaN          False   \nfreq             NaN          NaN           NaN          NaN            100   \nmean        5.843333     3.054000      3.758667     1.198667            NaN   \nstd         0.828066     0.433594      1.764420     0.763161            NaN   \nmin         4.300000     2.000000      1.000000     0.100000            NaN   \n25%         5.100000     2.800000      1.600000     0.300000            NaN   \n50%         5.800000     3.000000      4.350000     1.300000            NaN   \n75%         6.400000     3.300000      5.100000     1.800000            NaN   \nmax         7.900000     4.400000      6.900000     2.500000            NaN   \n\n       species_versicolor species_virginica  \ncount                 150               150  \nunique                  2                 2  \ntop                 False             False  \nfreq                  100               100  \nmean                  NaN               NaN  \nstd                   NaN               NaN  \nmin                   NaN               NaN  \n25%                   NaN               NaN  \n50%                   NaN               NaN  \n75%                   NaN               NaN  \nmax                   NaN               NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species_setosa</th>\n      <th>species_versicolor</th>\n      <th>species_virginica</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150</td>\n      <td>150</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.843333</td>\n      <td>3.054000</td>\n      <td>3.758667</td>\n      <td>1.198667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.828066</td>\n      <td>0.433594</td>\n      <td>1.764420</td>\n      <td>0.763161</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The following code produces this type of data, if it runs (but the list might be longer than I want to show here):\n\nNumpy Array\n----------\n [[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]","metadata":{}},{"cell_type":"code","source":"#print('\\nNumpy Array\\n----------\\n', X)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T18:19:02.291089Z","iopub.execute_input":"2024-03-05T18:19:02.291523Z","iopub.status.idle":"2024-03-05T18:19:02.296157Z","shell.execute_reply.started":"2024-03-05T18:19:02.291489Z","shell.execute_reply":"2024-03-05T18:19:02.295200Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"y = df.loc[:, 'species_versicolor']\ny = y.to_numpy()\n\n# Shuffle the two dataset in unison by creating a random index vector and applying it to both\nperm = np.random.permutation(len(X))\nX = X[perm]\ny = y[perm]\n#print(perm)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T18:39:18.806730Z","iopub.execute_input":"2024-03-06T18:39:18.807176Z","iopub.status.idle":"2024-03-06T18:39:18.818695Z","shell.execute_reply.started":"2024-03-06T18:39:18.807144Z","shell.execute_reply":"2024-03-06T18:39:18.817195Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Given that fit is called right after the Perceptron is created, some parameters could be passed to the initializer.\nclf = Perceptron(0.2)\nclf.fit(X, y, num_iteration = 40, feedback = 2)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T19:05:35.571631Z","iopub.execute_input":"2024-03-06T19:05:35.572025Z","iopub.status.idle":"2024-03-06T19:05:36.051350Z","shell.execute_reply.started":"2024-03-06T19:05:35.571995Z","shell.execute_reply":"2024-03-06T19:05:36.049469Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Given that fit is called right after the Perceptron is created, some parameters could be passed to the initializer.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m clf \u001b[38;5;241m=\u001b[39m Perceptron(\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeedback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[8], line 38\u001b[0m, in \u001b[0;36mPerceptron.fit\u001b[0;34m(self, X, y, learning_rate, num_iteration, feedback)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m learning_rate\u001b[38;5;241m*\u001b[39merror\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# first weight is the bias\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Force an error\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Update all parameters after bias\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# I changed this to start with range 1 to properly index weights. This works, (and\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# more closely represents the original code that this was taken from) \u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,num_feature\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"],"ename":"ZeroDivisionError","evalue":"division by zero","output_type":"error"}]},{"cell_type":"markdown","source":"Python Debugger\nI've spent a bunch of time searching and still have not found a way to get an interactive debugger with breakpoints. It is possible to get a debugger after an error has killed the app. Of course this is no where near as useful or powerful. Fascinating that pretty much no one points this out in all of the happy videos and articles talking about debugging notebooks. These tutorials spend the vast majority of their time disucssing their individual issues, rather than debugging in general. Arrrrrgggh!\n\nFor non-online notebooks you can use VSCode...\n\nI forced an error with a simple line: result = 5 / 0\n\nCommands\nu - back one step\nd - forward one step\np - print something (variable or expression)\nq - quit\n","metadata":{}},{"cell_type":"code","source":"%debug","metadata":{"execution":{"iopub.status.busy":"2024-03-06T19:05:45.800686Z","iopub.execute_input":"2024-03-06T19:05:45.801117Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"> \u001b[0;32m/tmp/ipykernel_33/1206212605.py\u001b[0m(38)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n\u001b[0;32m     36 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37 \u001b[0;31m            \u001b[0;31m# Force an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m---> 38 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40 \u001b[0;31m            \u001b[0;31m# Update all parameters after bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  p error\n"},{"name":"stdout","text":"-1.0\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  u\n"},{"name":"stdout","text":"> \u001b[0;32m/tmp/ipykernel_33/3169435832.py\u001b[0m(3)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m      1 \u001b[0;31m\u001b[0;31m# Given that fit is called right after the Perceptron is created, some parameters could be passed to the initializer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2 \u001b[0;31m\u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  d\n"},{"name":"stdout","text":"> \u001b[0;32m/tmp/ipykernel_33/1206212605.py\u001b[0m(38)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n\u001b[0;32m     36 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37 \u001b[0;31m            \u001b[0;31m# Force an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m---> 38 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40 \u001b[0;31m            \u001b[0;31m# Update all parameters after bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Results are not great, and jump back and forth...  I suspect something is wrong with the algorithm, or with the error calculation.","metadata":{}},{"cell_type":"code","source":"import random\n\nclass Perceptron():\n    '''\n        Perceptron Learning Algorithm that can be train using a \n        fit and predict methodology, without any library\n    '''\n    \n    def __init__(self):\n        self.weights = []\n        \n    def fit(self, X, y, learning_rate = 0.01, num_iteration = 100):\n        \n        num_row = len(X)\n        num_feature = len(X[0]) # Here we assume that we have a rectangular matrix\n        \n        # Randomly initalize the weights\n        for i in range(num_feature+1):\n            self.weights.append(random.uniform(0,1))\n        \n        # Launch the training algorithm\n        \n        for i in range(num_iteration):\n            \n            # Stochastic Gradient Descent\n            r_i = random.randint(0,num_row-1)\n            row = X[r_i]\n            yhat = self.predict(row)\n            error = (y[r_i] - yhat)\n            self.weights[0] = self.weights[0] + learning_rate*error\n\n#            for f_i in range(num_feature):\n#                self.weights[f_i] = self.weights[f_i] + learning_rate*error*row[f_i]\n            # I changed this to start with range 1 to properly index weights. This works, (and\n            # more closely represents the original code that this was taken from) \n            for f_i in range(1,num_feature+1):\n                self.weights[f_i] = self.weights[f_i] + learning_rate*error*row[f_i-1]\n                \n            if i % 100 == 0:\n                total_error = 0\n                for r_i in range(num_row):\n                    row = X[r_i]\n                    yhat = self.predict(row)\n                    error = (y[r_i] - yhat)\n                    total_error = total_error + error**2\n                mean_error = total_error/num_row\n                print(f\"Iteration {i} with error = {mean_error}\")\n        \n    def predict(self, row):\n            \n        # The activation start with the bias at weights == 0\n        activation = self.weights[0]\n        \n        # We iterate over the weights and the features in the given row\n        for weight, feature in zip(self.weights[1:], row):\n            activation = activation + weight*feature\n            \n        if activation >= 0.0:\n            return 1.0\n        return 0.0","metadata":{"execution":{"iopub.status.busy":"2024-03-05T18:24:12.655486Z","iopub.execute_input":"2024-03-05T18:24:12.656196Z","iopub.status.idle":"2024-03-05T18:24:12.672660Z","shell.execute_reply.started":"2024-03-05T18:24:12.656148Z","shell.execute_reply":"2024-03-05T18:24:12.671494Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import csv\n\ndef permute_together(X,y):\n    '''\n        Helper function to permute (shuffle) a matrix and a vector together\n    '''\n    \n    perm_X = []\n    perm_y = []\n    while len(X) != 0 and len(y) != 0:\n        \n        perm_id = random.randint(0,len(X)-1)\n        perm_X.append(X.pop(perm_id))\n        perm_y.append(y.pop(perm_id))\n        \n    return (perm_X, perm_y)\n\nclass DataFrame():\n    '''\n        Simple dataframe to mimick the pandas library\n    '''\n    def __init__(self):\n        self.header = [];\n        self.X = []\n        self.y = []\n        \n    def clean_string(self,string):\n        '''\n            Dummy function to clean up the iris dataset from (\")\n        '''\n        return string.replace('\"', '')\n    \n\n    def get_encoded_labels(self, target):\n        '''\n            Encode with 1 or 0 the y vector if it match our target variable\n        '''\n        labels = []\n        for label in self.y:\n            if label == target:\n                labels.append(1)\n            else:\n                labels.append(0)\n        return labels\n    \n    def read_csv(self, filename):\n        '''\n            Read the iris dataset CSV file and populate the header, the X and the y variables\n            needed for the perceptron\n        '''\n        with open(filename, newline='', encoding=\"utf-8-sig\") as csvfile:\n            csvreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n            \n            index = -1\n            for row in csvreader:\n                \n                # We have the header\n                if index == -1:\n                    self.header = [self.clean_string(s) for s in row[0].split(',')]\n                    index += 1\n                    continue\n                \n                # Here is the data\n                x = []\n                target = None\n                data = row[0].split(',')\n                for i in range(len(data)-1):\n                    x.append(float(data[i]))\n                \n                # Last item in the csv will be the target\n                self.y.append(self.clean_string(data[len(data)-1]))\n                self.X.append(x)\n                \n                index += 1\n        \n                \n\n# Data sets\ndf = DataFrame()\ndf.read_csv('/kaggle/input/iris-dataset/iris.csv')\n\nX = df.X\ny = df.get_encoded_labels('Versicolor') # encoding for 0 and 1\n\n# Shuffle the two dataset in unison\nX,y = permute_together(X,y)\n\nclf = Perceptron()\nclf.fit(X,y, num_iteration = 1000)","metadata":{"execution":{"iopub.status.busy":"2024-03-05T18:24:28.034449Z","iopub.execute_input":"2024-03-05T18:24:28.034853Z","iopub.status.idle":"2024-03-05T18:24:28.078910Z","shell.execute_reply.started":"2024-03-05T18:24:28.034823Z","shell.execute_reply":"2024-03-05T18:24:28.077212Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Iteration 0 with error = 1.0\nIteration 100 with error = 0.0\nIteration 200 with error = 0.0\nIteration 300 with error = 0.0\nIteration 400 with error = 0.0\nIteration 500 with error = 0.0\nIteration 600 with error = 0.0\nIteration 700 with error = 0.0\nIteration 800 with error = 0.0\nIteration 900 with error = 0.0\n","output_type":"stream"}]}]}